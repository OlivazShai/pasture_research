---
title: "Survey Data from IBGE"
author: "Shai Vaz"
date: "April 2024"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE}
# Data Wrangling
library(dplyr)
library(tidyr)
library(stringr)
library(readr)

# Graphics
library(ggplot2)

# Geographic
library(sf)
library(sidrar)
library(geobr)
library(datazoom.amazonia)

# Personal functions
source("../Functions/functions.R")
```

```{r, include=FALSE, eval=FALSE}

library(devtools)

# Sidrar development version
# Using a few changes that correct 
# for classific and category in 
# SIDRAR library

detach("package:sidrar", unload = T)
devtools::install_github("OlivazShai/sidrar", force = TRUE)
```

# Legal Amazon

We define states and municipalities in the Legal Amazon. All municipalities in the states are part of the LA, except for Maranhão, where only those left of the 14th meridian are considered.

```{r}
amazon_states = c(
  11:17, # Regiao Norte
  21, # Maranhão
  51 # Mato Grosso
  )
```

# PPM

## Loading data

Cattle stock by municipality, from 1995 to 2022.

```{r}
# Define list of geographic filters
# Some regions need division due to data limits

filter_list = list(
  # North
  list("Region" = 1),
  # Northeast
  list("State" = 21:24),
  list("State" = 25:29),
  # Southeast
  list("State" = 31:32),
  list("State" = c(33,35)), # there's no State 34
  # South
  list("Region" = 4),
  # Midwest
  list("Region" = 5)
)

# Initialise an empty data frame to store the aggregated data
ppm <- data.frame()

# Loop through each geo filter

for (filter in filter_list) {
  
  # Import data for the current region
  x <- get_sidra(
    x = 3939, # Efetivo dos rebanhos, por tipo de rebanho
    variable = 105,  # Efetivo dos rebanhos (Cabeças)
    period = as.character(1995:2022),
    classific = list("C79"), # Tipo de rebanho:
    category = list(2670), # Bovinos
    format = 4, # códigos e descrição
    geo = "City", # detalhe espacial
    geo.filter = filter
  )
  
  # Track job
  print(filter)
  
  # Append the data to the aggregated data frame
  ppm <- bind_rows(ppm, x)
}

rm(x, filter, filter_list)
```

## Cleaning

```{r}
cattle_heads_ppm <- ppm |> 
  select(
    "Valor",
    "Município (Código)",
    "Município",
    "Ano"
  ) |> 
  rename(
    cattle_heads = "Valor",
    code_muni = "Município (Código)",
    name_muni = "Município",
    year = "Ano"
  ) |> 
  mutate(
    name_state = str_split_i(name_muni, " - ", 2),
    code_state = str_sub(code_muni, start = 1, end = 2),
    name_muni = str_split_i(name_muni, " - ", 1)
  ) |> 
  relocate(year, code_muni, name_muni, code_state, name_state, cattle_heads)
```

I'll aggregate ppm data by AMC.

```{r}
cattle_heads_ppm <- cattle_heads_ppm |>
  left_join(
    muni_to_amc |> 
      as_tibble() |>
      select(code_amc, code_muni, code_biome, main_biome),
    
    by = "code_muni"
  ) |> 
  # dissolve by amc
  select( 
    year, cattle_heads, code_amc, code_biome, main_biome
  ) |> 
  summarise(
    cattle_heads = sum(cattle_heads, na.rm = TRUE),
    .by = c(year,code_amc, code_biome, main_biome)
  )
```

# Census 2017

## Loading data

I loop the loading on each of the 12 Variables of interest. First I define their codes, then their variable names. Cleaning is preformed during right after the download, so the resulting data frame already tidied-up.

```{r}
census_variables = c(
  
    2057, # Cattle heads - all farms
    9741, # Breeding cows >2yo - all farms

    # Discriminated by farm size (in heads) and finality
    
    9521, # Cattle heads - small farms (<50h)
    9523, # Sold heads - small farms
    9743, # Sale value - small farms

    2059, # Cattle heads - big farms (>50h)

    9525, # Breeding stock sold - big farms 
    9745, # Sale value Br.St. - big farms

    9527, # Sold for finishing - big farms 
    9747, # Sale value for finishing - big farms 

    9529, # Sold for slaughter - big farms
    9749 # Sale value for slaughter - big farms  
    )

census_names = c(
  "cattle_heads",
  "breed_cow_heads",
  
  "cattle_heads_small",
  "heads_sold_small",
  "sales_value_small",
  
  "cattle_heads_big",
  "heads_sold_big_breed",
  "sales_value_big_breed",
  
  "heads_sold_big_finish",
  "sales_value_big_finish",
  
  "heads_sold_big_slaughter",
  "sales_value_big_slaughter"
)
```

```{r}
for (i in 1:12) {
  census_name_i = census_names[i]
  census_variable_i = census_variables[i]
  print(i)
  
  census_i <- get_sidra(
    # Cattle headcounts and sales
    x = 6910,
    variable = census_variable_i,
    # By economic activity
    classific = "c12517",
    # Only cattle raising
    category = list("111523"), 
    # Municipality level data
    geo = "City",
    # Names and codes for geo levels  
    format = 3, 
    # Maximum digits
    digits = "max" 
  ) |> 
  # save as tibble
  as_tibble(
  ) |> 
  # Cleaning
  rename(
    "code_muni" = "Município (Código)",
    "name_muni" = "Município"
  ) |>
  rename_with(
    .cols = "Valor",
    .fn = \(x) census_name_i
  ) |> 
  select(
    name_muni,
    code_muni,
    {{census_name_i}}
  ) |> 
  mutate(
    name_state = str_split_i(name_muni, " - ", 2),
    code_state = str_sub(code_muni, start = 1, end = 2),
    name_muni = str_split_i(name_muni, " - ", 1)
  ) |> 
  relocate(name_muni, code_muni, name_state, code_state, {{census_name_i}})
  
  # Joining variables
  if (i == 1) {
    cattle_census_2017 = census_i
    print("done")
    
  } else {
    cattle_census_2017 = full_join(
      cattle_census_2017,
      census_i,
      by = join_by(
        "name_muni", "code_muni", "name_state", "code_state"
      )
    )
    
    print("done")
    rm(census_i)
    }
  
}

remove(census_name_i, census_variable_i, i)

```

Removing auxiliary variables.

```{r}
remove(census_names, census_variables)
```

## Average Prices in 2017

I'll aggregate by AMC, so first I need to source my municipality to AMC "translator".

```{r}
bulk_read_rds(muni_to_amc)
```

Now, I'll use census sales data to extract average cattle price per municipality. I only use sales **for slaughter** and **from larger farms**.

CORRECT THIS TO KEEP THE HEAD COUNTS!

```{r}
cattle_prices_census_2017 <- cattle_census_2017  |> 
  select(
   code_muni,
   name_muni,
   code_state,
   name_state,
   sales_value_big_slaughter,
   heads_sold_big_slaughter
  ) |> 
  # join amc
  left_join(
    muni_to_amc |> 
      as_tibble() |> 
      select(code_amc, code_muni, code_biome, main_biome),
    
    by = "code_muni"
  ) |> 
  select( 
    code_amc, code_biome, main_biome,
    sales_value_big_slaughter,
    heads_sold_big_slaughter
  ) |> 
  summarise(
    sales_value_big_slaughter = sum(sales_value_big_slaughter, na.rm = TRUE),
    heads_sold_big_slaughter = sum(heads_sold_big_slaughter, na.rm = TRUE),

    .by = c(code_amc, code_biome, main_biome)
  ) |>
  # average price by amc
  mutate(
    average_price =
      (sales_value_big_slaughter)/
      (heads_sold_big_slaughter)
  ) |>
  drop_na(
    average_price
  )
```

# Census 1995

## Loading data

```{r}
census_1995 <- get_sidra(
    x = 324, # Cattle headcounts and sales
    variable = 105, # Herd population
    classific = c(
      "c224", # Species
      "c219"  # Economic activity
      ), 
    category = list(
      c("4823"), # Species: Bovine
      c("4787")  # Activity: Livestock
      ), 
    geo = "City", # Municipality level data
    format = 3, # Names and codes for geo levels  
    digits = "max" # Maximum digits
  ) 
```

## Cleaning

```{r}
cattle_heads_census_1995 <- census_1995 |> 
  select(
    cattle_heads = Valor,
    code_muni = `Município (Código)`
  )
```

And by AMC.

```{r}
shares_by_amc <- left_join(
  cattle_heads_census_1995,
  # get amc data
  muni_to_amc |> 
    as_tibble() |> 
    select(code_amc, code_muni, code_biome, main_biome),
  
  by = "code_muni"
  ) |>
  # dissolve by amc
  select( 
    ! code_muni
  ) |> 
  summarise(
    cattle_heads = sum(cattle_heads, na.rm = TRUE),
    .by = c(code_amc, code_biome, main_biome)
  ) |> 
  # get proportion to totals
  mutate(
    share = cattle_heads / sum(cattle_heads, na.rm = TRUE)
  )
```

```{r}
bulk_write_rds(shares_by_amc)
```

# Census 2006

## Defining categories to load

```{r}
x = c(
  5450, # cattle heads, unspecified activty
  925, # cattle heads, big farms, specified activity
  930, # cattle sales, big farms
  930
  )

v = c(
  2057, # numero de cabeças
  2059, # numero de cabeças
  2067, # sold cattle heads
  2068  # value of sold cattle heads
  )

c = list(
  c("C3244", "C12551","C12552"),
  c("C12627", "C218", "C7940", "C12517", "C12625","C220"),
  c("C12645", "C218", "C7940", "C3244", "C12517", "C12625"),
  c("C12645", "C218", "C7940", "C3244", "C12517", "C12625")
  )

cat = list(
  list(0,0,0),
  # 111523 = activity: livestock
  list(0,0,0, 111523, 0,0),
  # "all" is to consider all categories for sale (slaughter, breed, etc)
  list("all", 0, 0, 0, 111523, 0),
  list("all", 0, 0, 0, 111523, 0)
  
  )

names = list(
  "cattle_heads",
  "cattle_heads_big",
  
  c(
    "heads_sold_big",
    "heads_sold_big_breed",
    "heads_sold_big_finish",
    "heads_sold_big_slaughter_young",
    "heads_sold_big_slaughter_male",
    "heads_sold_big_slaughter_female"
  ),
  
  c(
    "sales_value_big",
    "sales_value_big_breed",
    "sales_value_big_finish",
    "sales_value_big_slaughter_young",
    "sales_value_big_slaughter_male",
    "sales_value_big_slaughter_female"
  )
)
```

## Loading data

When loading, due to file size, segmentation is necessary. I apply a segmentation by region. For unknown reasons, the IGBE API returns repeated data, as some municipalities in Tocantins are classified as both from region 1 (Norte) and region 5 (Centro-oeste). The data returned is the same in both instances. To correct for this, I simply remove duplicated rows (which would not work if the data was different when loaded from each region). This correction only happens if duplicates are found, so if the API is updated the duplicate removal will be superfluous and won't be run.

This code is different to the loading of IBGE data from census 2017, because for that year, all relevant data comes from the same "Table", but from different "Variables". "Tables" are different sources and "Variables" are distinct informations in each Table. What constitutes a Table or a Variable in the IBGE database is somewhat arbitrary.

This code loops on Tables and on Regions. I also further segment the loading process, with a simpler approach used for tables 1 and 2, which don't have different classifications. For Table 3 (from which I get 2 variables), data is segmented by a classification, describing if sales are for breeding, finishing, or slaughter. Hence, for these Variables I also pivot the data before merging.

```{r}
for (i in 1:4) {
  name_i = names[[i]]
  
  # Show progress
  cat("Table: ", i ," - ",  name_i, "\n")
  
  
  ####################################################
  # For the first two tables
  
  if (i <= 2) {
    
    # Initialize an empty data frame for aggregated results
    census_aggregated <- tibble()
    
    # Inner loop through each geo filter
    for (j in 1:5) {
      
      # Show progress
      cat("Geo filter: Region ", j, "\n")
      
      census_i <- get_sidra(
        x = x[i], 
        variable = v[i],
        classific = c[[i]],
        category = cat[[i]],
        geo = "City", # Municipality level data
        geo.filter = list("Region" = j),  # Apply the current filter
        format = 3, # Names and codes  
        digits = "max" # Maximum digits
      ) |> 
      # save as tibble
      as_tibble() |> 
      # Cleaning
      rename(
        "code_muni" = "Município (Código)",
        "name_muni" = "Município"
      ) |>
      rename_with(
        .cols = "Valor",
        .fn = \(x) name_i
      ) |> 
      select(
        name_muni,
        code_muni,
        {{name_i}}
      )
      
      # Append results for the current filter to the aggregated data frame
      census_aggregated <- bind_rows(census_aggregated, census_i)
      
      
      # Checking for Duplicates
      
      if (any(duplicated(census_i))) {
        cat("Duplicates detected in census_i, region:", j)
      }
      
      if (any(duplicated(census_aggregated))) {
      
        cat(
          "Duplicates detected in census_aggregated, region ",
          j, 
          "\n Removing duplicates...")
        
        census_aggregated <- census_aggregated  |>
          distinct(
            name_muni, 
            code_muni,
            .keep_all = TRUE)
        }
      
    }
    
    # Use census_aggregated for further processing
    cattle_census_2006 <- if (i == 1) {
      census_aggregated
    } else {
      full_join(
        cattle_census_2006, 
        census_aggregated, 
        by = join_by(code_muni, name_muni)
        )
    }
    
    cat("done", "\n")
    
    ####################################################
    # For last two tables 
    
    } else {
    
    # Initialize for aggregated results
    census_aggregated <- tibble()
    
    # Inner loop through each geo filter
    for (j in 1:5) {
      
      # Show progress
      cat("Geo filter: Region ", j, "\n")
      
      census_i <- get_sidra(
        x = x[i], 
        variable = v[i],
        classific = c[[i]],
        category = cat[[i]],
        geo = "City", # Municipality level data
        geo.filter = list("Region" = j),  # Apply the current filter
        format = 3, # Names and codes  
        digits = "max" # Maximum digits
      ) |> 
      as_tibble() |> 
      select(
        "valor" = "Valor",
        "code_muni" = "Município (Código)",
        "name_muni" = "Município",
        "category" = "Movimento pecuário de bovinos vendidos nos estabelecimentos agropecuários com mais de 50 cabeças em 31/12"
      ) |> 
      pivot_wider(
        names_from = category,
        values_from = valor
      ) |> 
      rename_with(
        .cols = 3:8,
        .fn = \(x) name_i
      ) 
      
      # Append results for the current filter to the aggregated data frame
      census_aggregated <- bind_rows(census_aggregated, census_i)
    }
    
      # Checking for Duplicates
      if (any(duplicated(census_i))) {
        cat("Duplicates detected in census_i, region:", j)
      }
      
      if (any(duplicated(census_aggregated))) {
      
        cat(
          "Duplicates detected in census_aggregated, region ",
          j, 
          "\n Removing duplicates...")
        
        census_aggregated <- census_aggregated  |>
          distinct(
            name_muni, 
            code_muni,
            .keep_all = TRUE)
        }
    
    
    # Use census_aggregated for further processing
    cattle_census_2006 <- full_join(
      cattle_census_2006,
      census_aggregated,
      by = join_by(code_muni, name_muni)
    )
    
    cat("done", "\n")
  }
}

remove(name_i, i, j, census_i, census_aggregated)

```

And removing auxiliary variables.

```{r}
rm(x,v,c,cat,names)
```

## Average prices

# Saving RDS

```{r}
bulk_write_rds(cattle_census_2006)
```
